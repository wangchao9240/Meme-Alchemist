# Epic 3: LLM å†…å®¹ç”Ÿæˆç³»ç»Ÿ

**å²è¯— ID**: EPIC-3  
**ä¼˜å…ˆçº§**: P0  
**ä¼°ç®—**: 2-3 å¤©  
**ä¾èµ–**: EPIC-2 (JIT å–æ)  
**ç›®æ ‡**: é›†æˆ LLM APIï¼Œå®ç°åŸºäºäº‹å®çš„æ™ºèƒ½æ–‡æ¡ˆç”Ÿæˆï¼ŒåŒ…å«é™çº§ç­–ç•¥

---

## ä¸šåŠ¡ä»·å€¼

å°†é€‰å®šçš„äº‹å®è½¬åŒ–ä¸ºæœ‰è¶£çš„æ¢—å›¾æ–‡æ¡ˆï¼Œæ˜¯é¡¹ç›®çš„æ ¸å¿ƒä»·å€¼ã€‚é€šè¿‡é™çº§ç­–ç•¥ç¡®ä¿å³ä½¿ LLM å¤±è´¥ä¹Ÿèƒ½æä¾›åŸºç¡€åŠŸèƒ½ã€‚

---

## éªŒæ”¶æ ‡å‡†

- [ ] OpenAI API é›†æˆå®Œæˆ
- [ ] Structured Output ç¡®ä¿æ ¼å¼ä¸€è‡´
- [ ] 3 å±‚é™çº§ç­–ç•¥å®ç°ï¼ˆOpenAI â†’ Doubao â†’ æ¨¡æ¿ï¼‰
- [ ] ç”Ÿæˆæ—¶é—´ P95 < 8s
- [ ] 100% å“åº”å¯ç”¨ï¼ˆå«é™çº§ï¼‰
- [ ] ç”Ÿæˆå†…å®¹ç¬¦åˆ PRD schema

---

## ç”¨æˆ·æ•…äº‹

### Story 3.1: å®ç° OpenAI Service

**æ•…äº‹ ID**: EPIC3-S1  
**ä¼˜å…ˆçº§**: P0  
**ä¼°ç®—**: 1 å¤©

#### ä½œä¸º

åç«¯å¼€å‘è€…

#### æˆ‘æƒ³è¦

åˆ›å»º OpenAI API è°ƒç”¨æœåŠ¡

#### ä»¥ä¾¿äº

ç³»ç»Ÿå¯ä»¥ä½¿ç”¨ GPT-4o-mini ç”Ÿæˆæ–‡æ¡ˆ

#### éªŒæ”¶æ ‡å‡†

- [ ] åˆ›å»º `backend/src/services/llm/openai.ts`
- [ ] ä½¿ç”¨ Structured Outputï¼ˆJSON modeï¼‰
- [ ] å®ç°è¶…æ—¶æ§åˆ¶ï¼ˆ8sï¼‰
- [ ] é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘
- [ ] Token ä½¿ç”¨ç›‘æ§

#### æŠ€æœ¯ä»»åŠ¡

```typescript
// backend/src/services/llm/openai.ts
import OpenAI from "openai"
import type {
  ComposeRequest,
  ComposeResponse,
} from "@meme-alchemist/shared/types"

export class OpenAIService {
  private client: OpenAI

  constructor(apiKey: string) {
    this.client = new OpenAI({ apiKey })
  }

  async generateContent(
    request: ComposeRequest,
    timeout: number = 8000
  ): Promise<ComposeResponse> {
    const prompt = this.buildPrompt(request)

    const controller = new AbortController()
    const timeoutId = setTimeout(() => controller.abort(), timeout)

    try {
      const completion = await this.client.chat.completions.create(
        {
          model: "gpt-4o-mini",
          messages: [
            {
              role: "system",
              content: `ä½ æ˜¯ä¸€ä¸ªæ¢—å›¾æ–‡æ¡ˆåˆ›ä½œä¸“å®¶ã€‚æ ¹æ®æä¾›çš„äº‹å®ï¼Œåˆ›ä½œ${request.angle}é£æ ¼çš„å†…å®¹ã€‚
è¦æ±‚ï¼š
1. æ ‡é¢˜è¦å¸å¼•äººï¼ˆhookï¼‰
2. æ­£æ–‡è¦ç»“åˆæ‰€æœ‰äº‹å®ï¼Œè‡ªç„¶æµç•…
3. ä¿æŒäº‹å®å‡†ç¡®æ€§ï¼Œä¸ç¼–é€ å†…å®¹
4. è¾“å‡º JSON æ ¼å¼`,
            },
            {
              role: "user",
              content: prompt,
            },
          ],
          response_format: { type: "json_object" },
          temperature: 0.7,
          max_tokens: 1000,
        },
        {
          signal: controller.signal,
        }
      )

      clearTimeout(timeoutId)

      const content = JSON.parse(completion.choices[0].message.content!)

      return {
        topic: request.topic,
        angle: request.angle,
        hook: content.hook,
        body: content.body,
        facts: request.facts,
        platform_fit: content.platform_fit,
      }
    } catch (error) {
      clearTimeout(timeoutId)
      if (error.name === "AbortError") {
        throw new Error("OPENAI_TIMEOUT")
      }
      throw error
    }
  }

  private buildPrompt(request: ComposeRequest): string {
    const factsText = request.facts
      .map((f, i) => `${i + 1}. ${f.quote} (æ¥æº: ${f.source})`)
      .join("\n")

    return `è¯é¢˜: ${request.topic}
è§’åº¦: ${request.angle}
æ¨¡æ¿: ${request.template_id}

äº‹å®ç´ æ:
${factsText}

è¯·ç”Ÿæˆ JSON æ ¼å¼çš„å†…å®¹ï¼ŒåŒ…å«:
- hook: å¸å¼•äººçš„æ ‡é¢˜
- body: æ­£æ–‡ï¼ˆç»“åˆæ‰€æœ‰äº‹å®ï¼‰
- platform_fit: é€‚é…ä¸åŒå¹³å°çš„æ ¼å¼å»ºè®®`
  }
}
```

---

### Story 3.2: å®ç°é™çº§ç­–ç•¥

**æ•…äº‹ ID**: EPIC3-S2  
**ä¼˜å…ˆçº§**: P0  
**ä¼°ç®—**: 1 å¤©

#### ä½œä¸º

åç«¯å¼€å‘è€…

#### æˆ‘æƒ³è¦

å®ç° 3 å±‚é™çº§ç­–ç•¥ç¡®ä¿æœåŠ¡å¯ç”¨

#### ä»¥ä¾¿äº

å³ä½¿ OpenAI å¤±è´¥ç”¨æˆ·ä¹Ÿèƒ½ç”Ÿæˆå†…å®¹

#### éªŒæ”¶æ ‡å‡†

- [ ] P0: OpenAI (8s è¶…æ—¶)
- [ ] P1: Doubao (å¯é€‰ï¼Œ10s è¶…æ—¶)
- [ ] P2: æ¨¡æ¿åŒ–æ–‡æ¡ˆï¼ˆå¿…å®šæˆåŠŸï¼‰
- [ ] è‡ªåŠ¨é™çº§æ— éœ€äººå·¥å¹²é¢„
- [ ] è®°å½•é™çº§äº‹ä»¶åˆ°æ—¥å¿—

#### æŠ€æœ¯ä»»åŠ¡

```typescript
// backend/src/services/llm/orchestrator.ts
import { OpenAIService } from "./openai"
import { DouBaoService } from "./doubao" // å¯é€‰
import { TemplateFallback } from "./fallback"

export class LLMOrchestrator {
  private openai: OpenAIService
  private doubao?: DouBaoService
  private fallback: TemplateFallback

  constructor(openaiKey: string, doubaoKey?: string) {
    this.openai = new OpenAIService(openaiKey)
    if (doubaoKey) {
      this.doubao = new DouBaoService(doubaoKey)
    }
    this.fallback = new TemplateFallback()
  }

  async generate(request: ComposeRequest): Promise<ComposeResponse> {
    // P0: OpenAI
    try {
      console.log("[LLM] Trying OpenAI...")
      const result = await this.openai.generateContent(request, 8000)
      console.log("[LLM] OpenAI success")
      return result
    } catch (error) {
      console.warn("[LLM] OpenAI failed:", error.message)
    }

    // P1: Doubao (å¦‚æœé…ç½®)
    if (this.doubao) {
      try {
        console.log("[LLM] Trying Doubao...")
        const result = await this.doubao.generateContent(request, 10000)
        console.log("[LLM] Doubao success")
        return result
      } catch (error) {
        console.warn("[LLM] Doubao failed:", error.message)
      }
    }

    // P2: Template Fallback (å¿…å®šæˆåŠŸ)
    console.log("[LLM] Using template fallback")
    return this.fallback.generate(request)
  }
}
```

```typescript
// backend/src/services/llm/fallback.ts
export class TemplateFallback {
  generate(request: ComposeRequest): ComposeResponse {
    const hook = `å…³äº"${request.topic}"çš„${request.angle}è§£è¯»`

    const body = request.facts.map((f, i) => `ğŸ“Œ ${f.quote}`).join("\n\n")

    return {
      topic: request.topic,
      angle: request.angle,
      hook,
      body,
      facts: request.facts,
      platform_fit: [{ platform: "weibo", chars_max: 300, emoji_budget: 2 }],
    }
  }
}
```

---

### Story 3.3: æ›´æ–° Compose API

**æ•…äº‹ ID**: EPIC3-S3  
**ä¼˜å…ˆçº§**: P0  
**ä¼°ç®—**: 0.5 å¤©

#### ä½œä¸º

åç«¯å¼€å‘è€…

#### æˆ‘æƒ³è¦

å°† `/api/compose` åˆ‡æ¢åˆ°çœŸå® LLM æœåŠ¡

#### ä»¥ä¾¿äº

ç”ŸæˆçœŸå®çš„ AI æ–‡æ¡ˆ

#### éªŒæ”¶æ ‡å‡†

- [ ] é›†æˆ LLMOrchestrator
- [ ] ä¿æŒ API æ¥å£ä¸å˜
- [ ] æ·»åŠ é™çº§æç¤ºå¤´ï¼ˆX-LLM-Providerï¼‰
- [ ] è®°å½•ç”Ÿæˆè€—æ—¶

#### æŠ€æœ¯ä»»åŠ¡

```typescript
// backend/src/routes/compose.ts (æ›´æ–°)
import { LLMOrchestrator } from "../services/llm/orchestrator"

app.post("/", zValidator("json", ComposeRequestSchema), async (c) => {
  const request = c.req.valid("json")

  if (!c.env.OPENAI_API_KEY) {
    // ç›´æ¥ä½¿ç”¨æ¨¡æ¿é™çº§
    const fallback = new TemplateFallback()
    const response = fallback.generate(request)
    c.header("X-LLM-Provider", "fallback")
    return c.json(response)
  }

  try {
    const orchestrator = new LLMOrchestrator(
      c.env.OPENAI_API_KEY,
      c.env.DOUBAO_API_KEY
    )

    const startTime = Date.now()
    const response = await orchestrator.generate(request)
    const duration = Date.now() - startTime

    c.header("X-LLM-Duration", String(duration))
    c.header("X-LLM-Provider", "ai") // æˆ–è®°å½•å…·ä½“å“ªä¸ª provider

    console.log(`[Compose] Generated in ${duration}ms`)
    return c.json(response)
  } catch (error) {
    console.error("Compose error:", error)
    return c.json(
      {
        error: {
          code: "COMPOSE_FAILED",
          message: "Failed to generate content",
        },
      },
      500
    )
  }
})
```

---

### Story 3.4: å‰ç«¯é›†æˆä¸ UX ä¼˜åŒ–

**æ•…äº‹ ID**: EPIC3-S4  
**ä¼˜å…ˆçº§**: P1  
**ä¼°ç®—**: 0.5 å¤©

#### ä½œä¸º

å‰ç«¯å¼€å‘è€…

#### æˆ‘æƒ³è¦

ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹çš„ç”¨æˆ·ä½“éªŒ

#### ä»¥ä¾¿äº

ç”¨æˆ·äº†è§£ç”Ÿæˆè¿›åº¦å’ŒçŠ¶æ€

#### éªŒæ”¶æ ‡å‡†

- [ ] æ˜¾ç¤ºå®æ—¶è¿›åº¦ï¼ˆå–æ â†’ ç”Ÿæˆ â†’ æ¸²æŸ“ï¼‰
- [ ] æ˜¾ç¤ºé¢„ä¼°æ—¶é—´ï¼ˆ5-10sï¼‰
- [ ] é™çº§æ—¶æ˜¾ç¤ºæç¤º
- [ ] è¶…æ—¶åæ˜¾ç¤ºé‡è¯•æŒ‰é’®

#### æŠ€æœ¯ä»»åŠ¡

1. æ›´æ–° MemeViewer ç»„ä»¶
2. æ·»åŠ è¿›åº¦æ¡åŠ¨ç”»
3. æ£€æµ‹ X-LLM-Provider å¤´
4. æ˜¾ç¤ºé™çº§æç¤ºï¼ˆ"å½“å‰ä½¿ç”¨ç»å…¸æ¨¡æ¿"ï¼‰

---

## æˆæœ¬æ§åˆ¶

### Token é¢„ç®—

- å¹³å‡æ¯æ¬¡ç”Ÿæˆ: ~500 tokens
- æœˆç”Ÿæˆæ¬¡æ•°: 1000 æ¬¡
- æœˆæˆæœ¬: 1000 Ã— 500 / 1M Ã— $0.15 = **$0.075**

### ä¼˜åŒ–ç­–ç•¥

- ç²¾ç®€ system prompt
- é™åˆ¶ max_tokens
- ç¼“å­˜ç›¸åŒè¯·æ±‚ï¼ˆå¯é€‰ï¼‰

---

## æµ‹è¯•åœºæ™¯

### åœºæ™¯ 1: OpenAI æˆåŠŸ

- **Mock**: OpenAI API æ­£å¸¸
- **é¢„æœŸ**: 8s å†…è¿”å›é«˜è´¨é‡æ–‡æ¡ˆ
- **éªŒè¯**: JSON æ ¼å¼æ­£ç¡®ï¼ŒåŒ…å«æ‰€æœ‰äº‹å®

### åœºæ™¯ 2: OpenAI è¶…æ—¶

- **Mock**: API å»¶è¿Ÿ 10s
- **é¢„æœŸ**: è‡ªåŠ¨é™çº§åˆ° Doubao æˆ–æ¨¡æ¿
- **éªŒè¯**: ä»èƒ½è¿”å›å¯ç”¨å†…å®¹

### åœºæ™¯ 3: API Key ç¼ºå¤±

- **Mock**: æ—  OPENAI_API_KEY
- **é¢„æœŸ**: ç›´æ¥ä½¿ç”¨æ¨¡æ¿
- **éªŒè¯**: è¿”å›åŸºç¡€æ–‡æ¡ˆï¼Œæ ‡è®°ä¸º fallback

---

## å®Œæˆå®šä¹‰ (DoD)

- [ ] OpenAI Service å®ç°å¹¶æµ‹è¯•
- [ ] é™çº§ç­–ç•¥å®Œæ•´å®ç°
- [ ] API åˆ‡æ¢åˆ°çœŸå®æœåŠ¡
- [ ] å‰ç«¯ä½“éªŒä¼˜åŒ–
- [ ] æˆæœ¬ç›‘æ§åˆ°ä½
- [ ] æ‰€æœ‰æµ‹è¯•åœºæ™¯é€šè¿‡
- [ ] æ–‡æ¡£æ›´æ–°ï¼ˆAPI å¯†é’¥é…ç½®ï¼‰
